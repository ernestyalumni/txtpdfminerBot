{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# custom, written code\n",
    "from NLP_nltk import unique_everseen, levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Twitter samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'negative_tweets.json',\n",
       " u'positive_tweets.json',\n",
       " u'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets2015tweets = twitter_samples.strings('tweets.20150430-223406.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'RT @KirkKus: Indirect cost of the UK being in the EU is estimated to be costing Britain \\xa3170 billion per year! #BetterOffOut #UKIP',\n",
       " u'VIDEO: Sturgeon on post-election deals http://t.co/BTJwrpbmOY',\n",
       " u'RT @LabourEoin: The economy was growing 3 times faster on the day David Cameron became Prime Minister than it is today.. #BBCqt http://t.co\\u2026',\n",
       " u'RT @GregLauder: the UKIP east lothian candidate looks about 16 and still has an msn addy http://t.co/7eIU0c5Fm1',\n",
       " u\"RT @thesundaypeople: UKIP's housing spokesman rakes in \\xa3800k in housing benefit from migrants.  http://t.co/GVwb9Rcb4w http://t.co/c1AZxcLh\\u2026\",\n",
       " u'RT @Nigel_Farage: Make sure you tune in to #AskNigelFarage tonight on BBC 1 at 22:50! #UKIP http://t.co/ogHSc2Rsr2',\n",
       " u'RT @joannetallis: Ed Milliband is an embarrassment. Would you want him representing the UK?!  #bbcqt vote @Conservatives',\n",
       " u\"RT @abstex: The FT is backing the Tories. On an unrelated note, here's a photo of FT leader writer Jonathan Ford (next to Boris) http://t.c\\u2026\",\n",
       " u\"RT @NivenJ1: \\u201c@George_Osborne: Ed Miliband proved tonight why he's not up to the job\\u201d Tbf you've spent 5 years doing that you salivating do\\u2026\",\n",
       " u\"LOLZ to Trickle Down Wealth. It's never trickling past their own wallets. Greed always wins $$$ for the greedy.  https://t.co/X7deoPbS97\",\n",
       " u'SNP leader faces audience questions http://t.co/TYClKltSpW',\n",
       " u'RT @cononeilluk: Cameron \"Ed Milliband hanging out with Russell Brand. He is a joke. This is an election. This is about real people\\' http:/\\u2026',\n",
       " u'RT @politicshome: Ed Miliband: Last Labour government did not overspend http://t.co/W9RJ2aSH6o http://t.co/4myFekg5ex',\n",
       " u'If Miliband is refusing to do any deal with the SNP, how does he plan on forming a government?',\n",
       " u'RT @scotnotbritt: Well thats it. LABOUR would rather have a TORY government rather than work with the SNP. http://t.co/SNMkRDCe9f',\n",
       " u'Cameron wins last TV contest of election campaign - poll: LONDON (Reuters) - Prime Minister David Cameron won the\\u2026 http://t.co/aUMOoYWOSk',\n",
       " u'RT @stephen501: @dunleavy138 @CrillyBobc @theSNP @UKLabour I would be happy to do a deal with the SNP, but @Ed_Miliband was clear. If you w\\u2026',\n",
       " u'How dare @EdMiliband_MP force Socialists to chose between the English LP and the SNP! The #SNP are the last, true Socialist party in the UK',\n",
       " u'Watch: Ed Miliband trips off the stage following Question Time leaders special http://t.co/X61IGbe07R',\n",
       " u\"RT @abstex: The FT is backing the Tories. On an unrelated note, here's a photo of FT leader writer Jonathan Ford (next to Boris) http://t.c\\u2026\",\n",
       " u\"@B0MBSKARE the anti-Scottish feeling is largely a product of Tory press scaremongering. In practice most people won't give a toss!\",\n",
       " u'Miliband stumbles, Cameron dodges http://t.co/wnv2zOhQvq',\n",
       " u\"Miliband - I'd pass on PM job rather than do deal with Scots nationalists: LONDON (Reuters) - British Labour Party\\u2026 http://t.co/2cFGVfWkqF\",\n",
       " u\"RT @GloriaDePiero: Nick Clegg is just as responsible for this Govt's failing  plan as David Cameron - he's backed the Tories all the  way\",\n",
       " u'RT @mykilmarnock: Will the person who dropped a Vote SNP badge please call at Kilmarnock police station to collect it. http://t.co/o3sG5B4L\\u2026']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015tweets[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetstokens = twitter_samples.tokenized('negative_tweets.json')\n",
    "positivetweetstokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "tweets2015tokens = twitter_samples.tokenized('tweets.20150430-223406.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetstagged=nltk.pos_tag_sents(negativetweetstokens)\n",
    "positivetweetstagged=nltk.pos_tag_sents(positivetweetstokens)\n",
    "tweets2015tagged=nltk.pos_tag_sents(tweets2015tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "defaulttags = ['NN','JJ','NNP','CD','NNS','VBN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetsfiltered=[[item for item in sentence if item[1] in defaulttags] for sentence in negativetweetstagged]\n",
    "positivetweetsfiltered=[[item for item in sentence if item[1] in defaulttags] for sentence in positivetweetstagged]\n",
    "tweets2015filtered=[[item for item in sentence if item[1] in defaulttags] for sentence in tweets2015tagged]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## From my own defined Python function, `unique_everseen`, doing further preprocessing (i.e. data wrangling, data cleaning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetswordsonly=[list(unique_everseen([item[0] for item in tweet])) for tweet in negativetweetsfiltered]\n",
    "positivetweetswordsonly=[list(unique_everseen([item[0] for item in tweet])) for tweet in positivetweetsfiltered]\n",
    "tweets2015wordsonly=[list(unique_everseen([item[0] for item in tweet])) for tweet in tweets2015filtered]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativewords=list( set([word for tweet in negativetweetswordsonly for word in tweet]) )\n",
    "positivewords=list( set([word for tweet in positivetweetswordsonly for word in tweet]) )\n",
    "tweets2015words = list( set([word for tweet in tweets2015wordsonly for word in tweet]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19902"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets2015words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These are truly large datasets and when we will need to compute all possible pairs, $10^8$ computations will be needed.  Let's try a smaller dataset(s).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetswordsonly_small=negativetweetswordsonly[:500]\n",
    "positivetweetswordsonly_small=positivetweetswordsonly[:500]\n",
    "tweets2015wordsonly_small=tweets2015wordsonly[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativewords_small=list( set([word for tweet in negativetweetswordsonly_small for word in tweet]) )\n",
    "positivewords_small=list( set([word for tweet in positivetweetswordsonly_small for word in tweet]) )\n",
    "tweets2015words_small = list( set([word for tweet in tweets2015wordsonly_small for word in tweet]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set( tweets2015words ) == set( negativewords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(negativewords_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015wordsonly == positivetweetswordsonly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Levenshtein Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_distance(\"thesame\",\"thesame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_distance(\"positive\",\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print( levenshtein_distance(\"#thesame\",\"thesame\") ); \n",
    "print( levenshtein_distance(\"#thesame\",\"#thesame\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetsgr=nx.Graph()\n",
    "positivetweetsgr=nx.Graph()\n",
    "tweets2015gr=nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetsgr.add_nodes_from(negativewords)\n",
    "positivetweetsgr.add_nodes_from(positivewords)\n",
    "tweets2015gr.add_nodes_from(tweets2015words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for pair in list(itertools.combinations(negativetweetswordsonly,2) ):\n",
    "    for wordpair in list(itertools.product(pair[0],pair[1])):\n",
    "        firstString  = wordpair[0] \n",
    "        secondString = wordpair[1]\n",
    "        levDistance = levenshtein_distance(firstString,secondString)\n",
    "        negativetweetsgr.add_edge(firstString,secondString,weight=levDistance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Encapsulate all of this into a Python function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_edges_graph(V,tweets):\n",
    "    \"\"\"\n",
    "    build_edges_graph\n",
    "    \n",
    "    INPUT(S)/ARGUMENTS\n",
    "    ==================\n",
    "    V := (Python list of) (unique) vertices, V\n",
    "    tweets := (Python list of) tweets, from which we construct edges\n",
    "    \"\"\"\n",
    "    # Initialize an undirected graph \n",
    "    gr = nx.Graph() \n",
    "    gr.add_nodes_from(V)\n",
    "\n",
    "    for pair in list(itertools.combinations(tweets,2)):\n",
    "        for wordpair in list(itertools.product(pair[0],pair[1])):\n",
    "            firstString  = wordpair[0]\n",
    "            secondString = wordpair[1]\n",
    "            levDistance = levenshtein_distance(firstString,secondString)\n",
    "            gr.add_edge(firstString,secondString,weight=levDistance)\n",
    "\n",
    "    return gr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10632\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(negativewords))\n",
    "print(len(negativetweetswordsonly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetsgr_small = build_edges_graph(negativewords_small,negativetweetswordsonly_small)  # 5 minutes on Dell 15 inch Inspiron 7000 Gaming, 2017 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positivetweetsgr_small = build_edges_graph(positivewords_small,positivetweetswordsonly_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015gr_small = build_edges_graph(tweets2015words_small,tweets2015wordsonly_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "cf. [Converting to and from other data formats, NetworkX](https://networkx.github.io/documentation/networkx-1.10/reference/convert.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<397x397 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 155583 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.to_scipy_sparse_matrix(negativetweetsgr_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Checking to see that the number of nonzero entries, the stored elements in a Compressed Sparse Row format, is much greater than 0.5 relative to the total size of the matrix (number of columns * number of rows), we'll need to do dense math.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157609"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "397*397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2032904\n",
      "2018\n",
      "4072324\n"
     ]
    }
   ],
   "source": [
    "print(tweets2015gr_small.size())\n",
    "print(tweets2015gr_small.number_of_nodes())\n",
    "print(2018**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Make the graph be one suitable for a stochastic matrix:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015stochasticgr_small = nx.stochastic_graph( tweets2015gr_small.to_directed(), weight=\"weight\") # 2 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015stochasticnp_small = nx.to_numpy_matrix(tweets2015stochasticgr_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  0.00036346,  0.00024231, ...,  0.00024231,\n",
       "          0.00036346,  0.00036346],\n",
       "        [ 0.00039329,  0.        ,  0.00032774, ...,  0.00039329,\n",
       "          0.00032774,  0.00026219],\n",
       "        [ 0.00025203,  0.00031504,  0.        , ...,  0.00031504,\n",
       "          0.00031504,  0.00031504],\n",
       "        ..., \n",
       "        [ 0.00024105,  0.00036158,  0.00030131, ...,  0.        ,\n",
       "          0.00036158,  0.00036158],\n",
       "        [ 0.00039252,  0.0003271 ,  0.0003271 , ...,  0.00039252,\n",
       "          0.        ,  0.0003271 ],\n",
       "        [ 0.00038605,  0.00025737,  0.00032171, ...,  0.00038605,\n",
       "          0.00032171,  0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015stochasticnp_small;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00039971  0.00026647  0.00033309 ...,  0.00039971  0.00019985\n",
      "   0.00026647]]\n"
     ]
    }
   ],
   "source": [
    "for ele in tweets2015stochasticnp_small[5]:\n",
    "    print ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ways to store large numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015gr_smallHDF = h5py.File('tweets2015gr_small.h5','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"A\": shape (2018, 2018), type \"<f8\">"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015gr_smallHDF.create_dataset('A',data=nx.to_numpy_matrix( tweets2015gr_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015gr_smallHDF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"A\": shape (2018, 2018), type \"<f8\">"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015stochasticgr_smallHDF = h5py.File('tweets2015stochasticgr_small.h5','w')\n",
    "tweets2015stochasticgr_smallHDF.create_dataset('A',data=tweets2015stochasticnp_small )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015stochasticgr_smallHDF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015np_small= nx.to_numpy_matrix(tweets2015gr_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4072324"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015np_small.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'matrix' object has no attribute 'savetxt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-387c8a82aa66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets2015stochasticnp_small\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tweets2015stochasticgr_small.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'matrix' object has no attribute 'savetxt'"
     ]
    }
   ],
   "source": [
    "tweets2015stochasticnp_small.savetxt(\"tweets2015stochasticgr_small.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"tweets2015stochasticgr_small.txt\", tweets2015stochasticnp_small )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015gr_smallHDF = pd.HDFStore(\"tweets2015gr_small.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"../../../src/H5A.c\", line 259, in H5Acreate2\n    unable to create attribute\n  File \"../../../src/H5Aint.c\", line 275, in H5A_create\n    unable to create attribute in object header\n  File \"../../../src/H5Oattribute.c\", line 347, in H5O_attr_create\n    unable to create new attribute in header\n  File \"../../../src/H5Omessage.c\", line 224, in H5O_msg_append_real\n    unable to create new message\n  File \"../../../src/H5Omessage.c\", line 1945, in H5O_msg_alloc\n    unable to allocate space for message\n  File \"../../../src/H5Oalloc.c\", line 1142, in H5O_alloc\n    object header message is too large\n\nEnd of HDF5 error back trace\n\nCan't set attribute 'non_index_axes' in node:\n /A (Group) ''.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0a40c3e6be17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets2015gr_smallHDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_matrix\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtweets2015gr_small\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, key, value, format, append, columns, dropna, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         self._write_to_group(key, value, append=append, dropna=dropna,\n\u001b[0;32m--> 970\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     def append_to_multiple(self, d, value, selector, data_columns=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36m_write_to_group\u001b[0;34m(self, key, value, format, index, append, complib, encoding, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;31m# write the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_table\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, obj, axes, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, **kwargs)\u001b[0m\n\u001b[1;32m   3864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3865\u001b[0m             \u001b[0;31m# set the table attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3866\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3868\u001b[0m             \u001b[0;31m# create the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mset_attrs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_index_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_index_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_rep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/tables/attributeset.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Set the attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g__setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;31m# Log new attribute addition.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/tables/attributeset.pyc\u001b[0m in \u001b[0;36m_g__setattr\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# New attribute or value. Introduce it into the local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.AttributeSet._g_setattr (tables/hdf5extension.c:7824)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"../../../src/H5A.c\", line 259, in H5Acreate2\n    unable to create attribute\n  File \"../../../src/H5Aint.c\", line 275, in H5A_create\n    unable to create attribute in object header\n  File \"../../../src/H5Oattribute.c\", line 347, in H5O_attr_create\n    unable to create new attribute in header\n  File \"../../../src/H5Omessage.c\", line 224, in H5O_msg_append_real\n    unable to create new message\n  File \"../../../src/H5Omessage.c\", line 1945, in H5O_msg_alloc\n    unable to allocate space for message\n  File \"../../../src/H5Oalloc.c\", line 1142, in H5O_alloc\n    object header message is too large\n\nEnd of HDF5 error back trace\n\nCan't set attribute 'non_index_axes' in node:\n /A (Group) ''."
     ]
    }
   ],
   "source": [
    "tweets2015gr_smallHDF.append(\"A\", pd.DataFrame(nx.to_numpy_matrix( tweets2015gr_small ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save the nodes of the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f=open(\"tweets2015grnodes_small.pkl\",\"wb\")\n",
    "pickle.dump(tweets2015gr_small.nodes(),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( tweets2015gr_small.nodes() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negative_nparr = nx.to_numpy_matrix(negativetweetsgr_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positive_nparr = nx.to_numpy_matrix(positivetweetsgr_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015_nparr = nx.to_numpy_matrix(tweets2015gr_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015gr_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157609\n",
      "210681\n",
      "393129\n"
     ]
    }
   ],
   "source": [
    "print(negative_nparr.size)\n",
    "print(positive_nparr.size)\n",
    "print(tweets2015_nparr.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318\n",
      "10632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1318"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativetweetsgr_trial.edges();\n",
    "print(negativetweetsgr_trial.number_of_edges());\n",
    "print(negativetweetsgr_trial.number_of_nodes());\n",
    "negativetweetsgr_trial.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Doing pagerank with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets2015_pagerank = nx.pagerank(tweets2015gr_small,weight=\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that this caused my kernel to freeze.  My system is a 2017 Dell 15 in. Inspiron 7000 Gaming, with 8 GB RAM.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA C/C++ CUBLAS to the rescue: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `main_pagerank.exe` (this was made by compiling with this command)   \n",
    "\n",
    "```    \n",
    "nvcc -std=c++11 -arch='sm_61' -lcublas main_pagerank.cu pagerank.cu -o main_pagerank.exe    \n",
    "```   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pagerankresultfile = open(\"Pagerankresult.txt\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pagerankresultlist = []\n",
    "for line in pagerankresultfile:\n",
    "    pagerankresultlist.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pagerankresultlist = pagerankresultlist[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "1.000001126\n"
     ]
    }
   ],
   "source": [
    "print(len(pagerankresultlist))\n",
    "pagerankresultlist = [float(ele) for ele in pagerankresultlist]\n",
    "print(sum(pagerankresultlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-76164c88dabf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets2015grnodes_smallpkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tweets2015grnodes_small.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tweets2015grnodes_smallpkl = pickle.load(open(\"tweets2015grnodes_small.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets2015grnodes_smallfile = open(\"tweets2015grnodes_small.pkl\",'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets2015grnodes_smalllist= []\n",
    "for line in tweets2015grnodes_smallfile:\n",
    "    tweets2015grnodes_smalllist.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3945\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets2015grnodes_smalllist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(lp0\\n',\n",
       " 'Vyellow\\n',\n",
       " 'p1\\n',\n",
       " 'aVfour\\n',\n",
       " 'p2\\n',\n",
       " 'aVknell\\n',\n",
       " 'p3\\n',\n",
       " 'aVhttp://t.co/ShXTCyJSgw\\n',\n",
       " 'p4\\n',\n",
       " \"aVtonight's\\n\",\n",
       " 'p5\\n',\n",
       " 'aVvotes\\n',\n",
       " 'p6\\n',\n",
       " 'aVvoter\\n',\n",
       " 'p7\\n',\n",
       " 'aVWatch\\n',\n",
       " 'p8\\n',\n",
       " 'aVpost-election\\n',\n",
       " 'p9\\n',\n",
       " 'aVvoted\\n',\n",
       " 'p10\\n',\n",
       " 'aVwhatsoever\\n',\n",
       " 'p11\\n',\n",
       " 'aVsorry\\n',\n",
       " 'p12\\n',\n",
       " 'aVeditorship\\n',\n",
       " 'p13\\n',\n",
       " 'aVworth\\n',\n",
       " 'p14\\n',\n",
       " 'aV@SkyNews\\n',\n",
       " 'p15\\n',\n",
       " 'aVClegg\\n',\n",
       " 'p16\\n',\n",
       " 'aVGE\\n',\n",
       " 'p17\\n',\n",
       " 'aVbringing\\n',\n",
       " 'p18\\n',\n",
       " 'aVvast\\n',\n",
       " 'p19\\n',\n",
       " \"aVwe'll\\n\",\n",
       " 'p20\\n',\n",
       " 'aV@Independent\\n',\n",
       " 'p21\\n',\n",
       " 'aV@NursieDear25\\n',\n",
       " 'p22\\n',\n",
       " 'aVcalled\\n',\n",
       " 'p23\\n',\n",
       " 'aVunrelated\\n',\n",
       " 'p24\\n',\n",
       " 'aVred\\n',\n",
       " 'p25\\n',\n",
       " 'aVSNP\\n',\n",
       " 'p26\\n',\n",
       " 'aVLeanne\\n',\n",
       " 'p27\\n',\n",
       " 'aVforce\\n',\n",
       " 'p28\\n',\n",
       " 'aVleaders\\n',\n",
       " 'p29\\n',\n",
       " 'aVtired\\n',\n",
       " 'p30\\n',\n",
       " 'aVhttp://t.co/PjP3yb5u6t\\n',\n",
       " 'p31\\n',\n",
       " 'aV@mark_stuart10\\n',\n",
       " 'p32\\n',\n",
       " 'aVhttps://t.co/k4NMrenulf\\n',\n",
       " 'p33\\n',\n",
       " 'aVpunning\\n',\n",
       " 'p34\\n',\n",
       " 'aVbudget\\n',\n",
       " 'p35\\n',\n",
       " 'aVsecond\\n',\n",
       " 'p36\\n',\n",
       " 'aV7th\\n',\n",
       " 'p37\\n',\n",
       " 'aVestimated\\n',\n",
       " 'p38\\n',\n",
       " 'aVblue\\n',\n",
       " 'p39\\n',\n",
       " 'aV@LibDem\\n',\n",
       " 'p40\\n',\n",
       " 'aVKilmarnock\\n',\n",
       " 'p41\\n',\n",
       " 'aV+\\n',\n",
       " 'p42\\n',\n",
       " 'aV#torycull\\n',\n",
       " 'p43\\n',\n",
       " \"aVCameron's\\n\",\n",
       " 'p44\\n',\n",
       " 'aVspokesman\\n',\n",
       " 'p45\\n',\n",
       " 'aV@jamesosh\\n',\n",
       " 'p46\\n',\n",
       " 'aVnew\\n',\n",
       " 'p47\\n',\n",
       " 'aVPresidential\\n',\n",
       " 'p48\\n',\n",
       " 'aV@bratdha\\n',\n",
       " 'p49\\n',\n",
       " 'aVmen\\n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015grnodes_smalllist[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'yellow',\n",
       " u'four',\n",
       " u'knell',\n",
       " u'http://t.co/ShXTCyJSgw',\n",
       " u\"tonight's\",\n",
       " u'votes',\n",
       " u'voter',\n",
       " u'Watch',\n",
       " u'post-election',\n",
       " u'voted',\n",
       " u'whatsoever',\n",
       " u'sorry',\n",
       " u'editorship',\n",
       " u'worth',\n",
       " u'@SkyNews',\n",
       " u'Clegg',\n",
       " u'GE',\n",
       " u'bringing',\n",
       " u'vast',\n",
       " u\"we'll\",\n",
       " u'@Independent',\n",
       " u'@NursieDear25',\n",
       " u'called',\n",
       " u'unrelated',\n",
       " u'red',\n",
       " u'SNP',\n",
       " u'Leanne',\n",
       " u'force',\n",
       " u'leaders',\n",
       " u'tired',\n",
       " u'http://t.co/PjP3yb5u6t',\n",
       " u'@mark_stuart10',\n",
       " u'https://t.co/k4NMrenulf',\n",
       " u'punning',\n",
       " u'budget',\n",
       " u'second',\n",
       " u'7th',\n",
       " u'estimated',\n",
       " u'blue',\n",
       " u'@LibDem',\n",
       " u'Kilmarnock',\n",
       " u'+',\n",
       " u'#torycull',\n",
       " u\"Cameron's\",\n",
       " u'spokesman',\n",
       " u'@jamesosh',\n",
       " u'new',\n",
       " u'Presidential',\n",
       " u'@bratdha',\n",
       " u'men',\n",
       " u'nowt',\n",
       " u'becm',\n",
       " u'GRN',\n",
       " u'100',\n",
       " u'celebration',\n",
       " u'@scottieh419',\n",
       " u'kids',\n",
       " u'rests',\n",
       " u'muddying',\n",
       " u'reports',\n",
       " u'NOT',\n",
       " u'aka',\n",
       " u\"someone's\",\n",
       " u'changes',\n",
       " u'Bingo',\n",
       " u'plea',\n",
       " u'campaign',\n",
       " u\"DON'T\",\n",
       " u'@Socialist',\n",
       " u'FUCK',\n",
       " u'foodbanks',\n",
       " u'Book',\n",
       " u'Wales',\n",
       " u'total',\n",
       " u'http://t.co/ZgZbSwnZxZ',\n",
       " u'opponents',\n",
       " u'Hosie',\n",
       " u'army',\n",
       " u'hospital',\n",
       " u'arms',\n",
       " u\"They'd\",\n",
       " u'call',\n",
       " u'passport',\n",
       " u'http://t.co/HecQfHgRLn',\n",
       " u'type',\n",
       " u'@LucyMPowell',\n",
       " u'@KirkKus',\n",
       " u'@GAPonsonby',\n",
       " u'supporters',\n",
       " u'http://t.co/iWtN4HF9mj',\n",
       " u'@DavidSalocin',\n",
       " u'adult',\n",
       " u'V',\n",
       " u'http://t.co/ttIqotQMPR',\n",
       " u'circumstances',\n",
       " u'Crazy',\n",
       " u'Financial',\n",
       " u'room',\n",
       " u'3200',\n",
       " u'ed']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2015gr_small.nodes()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if pickle/pickling fails, then rebuilding the graph with its node, and assuming that the order of nodes is the same as before, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets2015gr_small.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pageranktweets2015results = zip(tweets2015gr_small.nodes(), pagerankresultlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'May', 0.00107337),\n",
       " (u'sketch', 0.00106792),\n",
       " (u'poverty', 0.00106506),\n",
       " (u'Carswell', 0.00106405),\n",
       " (u'favours', 0.00106181),\n",
       " (u'Strong', 0.00106171),\n",
       " (u'yourself', 0.00106052),\n",
       " (u'SNP.Tim', 0.00106006),\n",
       " (u'Liam', 0.00105989),\n",
       " (u'@TheMockneyRebel', 0.00105888),\n",
       " (u'@jreynoldsMP', 0.00105595),\n",
       " (u'turns', 0.00105517),\n",
       " (u'wonder', 0.0010536),\n",
       " (u'Worked', 0.00105347),\n",
       " (u'Voting', 0.00105171),\n",
       " (u\"Here's\", 0.00105133),\n",
       " (u'37', 0.00104981),\n",
       " (u'Vine', 0.00104812),\n",
       " (u'various', 0.0010408),\n",
       " (u'@mark_stuart10', 0.00103613),\n",
       " (u\"Labour's\", 0.00103214),\n",
       " (u'time', 0.00103193),\n",
       " (u'http://t.co/4\\u2026', 0.0010311),\n",
       " (u'banks', 0.0010308),\n",
       " (u'#r4today', 0.00103022),\n",
       " (u'#VoteLabour', 0.00103017),\n",
       " (u'chances', 0.00102981),\n",
       " (u'@DonaldLiddell', 0.0010289),\n",
       " (u'#cullthetories', 0.00102863),\n",
       " (u'Dave', 0.00102825),\n",
       " (u'history', 0.0010282),\n",
       " (u'http://t\\u2026', 0.0010281),\n",
       " (u'overspent', 0.00102767),\n",
       " (u'@ThimbleOfGrace', 0.00102698),\n",
       " (u'http://t.co/7eIU0c5Fm1', 0.00102615),\n",
       " (u'@HTScotPol', 0.00102597),\n",
       " (u'#davidcamerontweet', 0.00102537),\n",
       " (u'trip', 0.00102532),\n",
       " (u'expand', 0.00102436),\n",
       " (u'Must', 0.00102436),\n",
       " (u'hahahaha', 0.00102426),\n",
       " (u'fellow', 0.0010237),\n",
       " (u'tired', 0.00102325),\n",
       " (u'Eng', 0.00102312),\n",
       " (u'V', 0.0010231),\n",
       " (u'@IanBarr67', 0.00102305),\n",
       " (u'headline', 0.00102282),\n",
       " (u'ah', 0.00102246),\n",
       " (u'Margaret', 0.00102241),\n",
       " (u'results', 0.00102214),\n",
       " (u'audience', 0.00102166),\n",
       " (u'@UtopianFireman', 0.00102156),\n",
       " (u'http://t.co/ShXTCyJSgw', 0.00102153),\n",
       " (u'ruled', 0.00102087),\n",
       " (u'Byrne', 0.0010206),\n",
       " (u'Everyone', 0.00102044),\n",
       " (u'nicola', 0.00102017),\n",
       " (u'news', 0.00102017),\n",
       " (u'voters', 0.00102004),\n",
       " (u'@BenCooper86', 0.001019),\n",
       " (u'Make', 0.00101868),\n",
       " (u'total', 0.00101807),\n",
       " (u'Canal', 0.00101802),\n",
       " (u\"Sturgeon's\", 0.00101799),\n",
       " (u'@Nigel_Farage', 0.00101799),\n",
       " (u'burden', 0.00101762),\n",
       " (u'forces', 0.00101668),\n",
       " (u'nationalist', 0.0010165),\n",
       " (u'http://t.co/cfhNO9C3\\u2026', 0.0010164),\n",
       " (u'full', 0.00101633),\n",
       " (u'#isitok', 0.0010163),\n",
       " (u'Smashing', 0.00101605),\n",
       " (u'Bet', 0.0010158),\n",
       " (u'billion', 0.00101555),\n",
       " (u'Nobody', 0.00101555)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( reversed( sorted(pageranktweets2015results, key=lambda x: x[1])[-75:]  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__iter__',\n",
       " '__len__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add_cycle',\n",
       " 'add_edge',\n",
       " 'add_edges_from',\n",
       " 'add_node',\n",
       " 'add_nodes_from',\n",
       " 'add_path',\n",
       " 'add_star',\n",
       " 'add_weighted_edges_from',\n",
       " 'adj',\n",
       " 'adjacency_iter',\n",
       " 'adjacency_list',\n",
       " 'adjlist_dict_factory',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'degree',\n",
       " 'degree_iter',\n",
       " 'edge',\n",
       " 'edge_attr_dict_factory',\n",
       " 'edges',\n",
       " 'edges_iter',\n",
       " 'get_edge_data',\n",
       " 'graph',\n",
       " 'has_edge',\n",
       " 'has_node',\n",
       " 'is_directed',\n",
       " 'is_multigraph',\n",
       " 'name',\n",
       " 'nbunch_iter',\n",
       " 'neighbors',\n",
       " 'neighbors_iter',\n",
       " 'node',\n",
       " 'node_dict_factory',\n",
       " 'nodes',\n",
       " 'nodes_iter',\n",
       " 'nodes_with_selfloops',\n",
       " 'number_of_edges',\n",
       " 'number_of_nodes',\n",
       " 'number_of_selfloops',\n",
       " 'order',\n",
       " 'remove_edge',\n",
       " 'remove_edges_from',\n",
       " 'remove_node',\n",
       " 'remove_nodes_from',\n",
       " 'selfloop_edges',\n",
       " 'size',\n",
       " 'subgraph',\n",
       " 'to_directed',\n",
       " 'to_undirected']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(negativetweetsgr_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dir(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negativetweetsgr = build_edges_graph(negativewords, negativetweetswordsonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "8\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for wordpair in list(itertools.product(pair2[0], pair2[1] ) ):\n",
    "    print( levenshtein_distance( wordpair[0], wordpair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
